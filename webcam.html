<!DOCTYPE html>
<html lang="en">

<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1.0">
	<title>Camera</title>
	<script src="https://docs.opencv.org/3.4.0/opencv.js" type="text/javascript"></script>
	<style>
		body,
		html {
			margin: 0;
			padding: 0;
			height: 100%;
			display: flex;
			align-items: center;
			justify-content: center;
			position: relative;
			font-family: Arial, sans-serif;
		}

		#canvasOutput {
			border: 2px solid black;
		}

		#nextPage {
			position: absolute;
			top: 20px;
			right: 20px;
			font-size: 24px;
			cursor: pointer;
			background: none;
			border: none;
			color: blue;
		}
	</style>
</head>

<body>
	<video id="videoInput" playsinline autoplay></video>
	<canvas id="canvasOutput"></canvas>
	<button id="nextPage" onclick="window.location.href='next-page.html'">&#10145;</button> <!-- Unicode right arrow -->
	<script>
		function onOpenCvReady() {
			document.getElementById('videoInput').style.display = 'block';
			let video = document.getElementById('videoInput');
			let canvas = document.getElementById('canvasOutput');
			let context = canvas.getContext('2d');

			navigator.mediaDevices.getUserMedia({video: true, audio: false})
				.then(function (stream) {
					video.srcObject = stream;
					video.play();
				})
				.catch(function (err) {
					console.log("An error occurred: " + err);
				});

			video.addEventListener('loadeddata', function () {
				canvas.width = video.videoWidth;
				canvas.height = video.videoHeight;

				let src = new cv.Mat(video.height, video.width, cv.CV_8UC4);
				let gray = new cv.Mat();
				let faces = new cv.RectVector();
				let classifier = new cv.CascadeClassifier();

				// Load the cascade
				cv.FS_createLazyFile('/', 'haarcascade_frontalface_default.xml', 'haarcascade_frontalface_default.xml', true, false);
				classifier.load('haarcascade_frontalface_default.xml');

				function processVideo() {
					if (video.paused || video.ended) {
						src.delete(); gray.delete(); faces.delete(); classifier.delete();
						return;
					}
					context.drawImage(video, 0, 0, video.width, video.height);
					src.data.set(context.getImageData(0, 0, video.width, video.height).data);
					cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY);
					classifier.detectMultiScale(gray, faces, 1.1, 3, 0);
					for (let i = 0; i < faces.size(); i++) {
						let face = faces.get(i);
						let point1 = new cv.Point(face.x, face.y);
						let point2 = new cv.Point(face.x + face.width, face.y + face.height);
						cv.rectangle(src, point1, point2, [255, 0, 0, 255]);
					}
					cv.imshow('canvasOutput', src);
					requestAnimationFrame(processVideo);
				}

				requestAnimationFrame(processVideo);
			});
		}
		document.addEventListener('DOMContentLoaded', onOpenCvReady);
	</script>
</body>

</html>